---
layout: note
title: Book notes&#58; Presumptive meanings
date: March 2018
---

*Presumptive meanings.* Stephen Levinson. MIT Press, 2000.

# Introduction

> First principles even seem to suggest that the recovery of a speaker's intentions on the basis of what he has said is in principle impossible. &hellip; What I have tried to do in this book is detach a little part of this problem and argue that **there must be powerful heuristics that give us preferred interpretations without too much calculation** of such matters as speakers' intentions, encyclopedic knowledge of the domain being talked about, or calculations of others' mental processes. Such preferred interpretations may be overridden by, and are certainly supplemented with, calculations of just this complex kind. But it seems implausible that the phenomenology of instantaneous, determinate interpretation could be delivered solely by reasoning about such matters as the potentially infinite regress of what the speaker is thinking the hearer will think that the speaker is thinking, and so on, ad infinitum. (4–5)

Important to Levinson: provide an account of meaning that allows for incremental processing.

In the context of Levinson "showing his cards" on related topics not directly treated by the book, he makes this bold claim (and several others):

> There is no scheme of the kind that syntactic structures [and lexical information!] are mapped onto semantic structures which themselves represent full-fledged propositions, these semantic structures being the input into pragmatics, which yields additional inferences or restrictions on meaning. &hellip; Instead, I argue, we should stop thinking of the distinction in terms of levels of representation. Instead, we should think about both semantics and pragmatics as being component processes that offer their own distinctive contributions to a single level of representation. (8–9)

# Generalized conversational implicature

## A review of Gricean pragmatics

Grice's theory of utterer's meaning:

> $S$ means<sub>nn</sub> $p$ by "uttering" $U$ to $A$ iff $S$ intends:
>
> 1. $A$ to think $p$
> 2. $A$ to recognize that $S$ intends 1.
> 3. $A$'s recognition of $S$'s intending 1. to be the prime reason for $A$ thinking $p$

> In this scheme, what is *coded* by the linguistic system is the sum of what is *said* (roughly the truth-conditional content) and what is *conventionally implicated*. In contrast, what is *conversationally* implicated is not coded but rather inferred on the basis of some basic assumptions about the rational nature of conversational activity, as stated in the Cooperative Principle and its constituent maxims of conversations. (14)

Distinctive properties of conversational implicatures:

- **Cancellability**
- **Nondetachability:** any expression with the same coded content will tend to carry the same implicatures [but Manner is an exception]
- **Calculability:** can transparently derive inference from premises about rational nature of conversation
- **Nonconventionality:** noncoded nature of inferences, parasitic on what is actually coded
- **Reinforceability:** often possible to add explicitly what has been implicated, with less a sense of redundancy than if one simply repeats the coded content
- **Universality** [should follow from "calculability," assuming listeners are equally rational!]

Particularized vs. generalized conversational implicatures:

> - An implicature $i$ from utterance $U$ is *particularized* iff $U$ implicates $i$ only by virtue of specific contextual assumptions that would not invariably or even normally obtain
> - An implicature $i$ is *generalized* iff $U$ implicates $i$ *unless* there are unusual specific contextual assumptions that defeat it

> A: "What time is it?"
>
> B: "Some of the guests are already leaving." [PCI: "It must be late."; GCI: "Not all of the guests are already leaving."]

Hard to distinguish GCIs from conventional meaning. Levinson argues (quoting Grice) that this mistake has been made quite a bit in the past. "It is the fact that the inferences *normally* accompany the connectives that gives rise to the temptation to view them as part of the coded content, with all the analytical mistakes that would follow" (20).
